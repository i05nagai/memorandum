---
title: Chapter1. Mathematical background
book_title: Theory and method of Bayes Statistics
book_chapter: 1
book_section: 2
---

## 1.2 Metrics


### 1.2.1 Partition function and free energy

$$
\begin{eqnarray}
    \int_{\mathbb{R}}
    \ dx_{1}
    \int_{\mathbb{R}}
    \ dx_{2}
    \cdots
    \int_{\mathbb{R}}
    \ dx_{n}
    Z_{n}(X^{n}; 1)
    & = &
        \int_{\mathbb{R}}
        \ dx_{1}
        \int_{\mathbb{R}}
        \ dx_{2}
        \cdots
        \int_{\mathbb{R}}
        \ dx_{n}
        \left(
            \int_{\mathbb{R}}
                \phi(w)
            \ dw
            \prod_{i = 1}^{n}
                p(x_{i} \mid w)
        \right)
    \nonumber
    \\
    & = &
        \int_{\mathbb{R}}
            \phi(w)
        \ dw
        \int_{\mathbb{R}}
        \ dx_{1}
        \int_{\mathbb{R}}
        \ dx_{2}
        \cdots
        \int_{\mathbb{R}}
        \ dx_{n}
        \left(
            \prod_{i = 1}^{n}
                p(x_{i} \mid w)
        \right)
    \nonumber
    \\
    & = &
        \int_{\mathbb{R}}
            \phi(w)
        \ dw
        \prod_{i = 1}^{n}
        \left(
            \int_{\mathbb{R}}
            \ dx_{i}
            p(x_{i} \mid w)
        \right)
    \nonumber
    \\
    & = &
        \int_{\mathbb{R}}
            \phi(w)
        \ dw
    \nonumber
    \\
    & = &
        1
    .
    \nonumber
\end{eqnarray}
$$

By our assumption (even though not clearly mentioned in the book), true distribution of $X^{n}$ is given by

$$
    q_{X^{n}}
    (X^{n})
    =
    \prod_{i = 1}^{n}
        q(X_{i})
    .
$$

On the other hand, $Z_{n}(X^{n}; 1)$ is the distribution of $X^{n}$ estimated by our statistical model and our prior distribution.
That is

$$
\begin{eqnarray}
    p(x^{n})
    & := &
        Z_{n}(x^{n}; 1)
    \nonumber
    \\
    & = &
        \int_{W}
            \phi(w)
            \prod_{i=1}^{n}
                p(X_{i} \mid w)
        \ dw
\end{eqnarray}
$$

#### Definition. free energy
Let

$$
    F_{n}(\beta)
    :=
    -
    \frac{1}{\beta}
    \log Z_{n}(\beta)
    .
$$

$F_{n}(\beta)$ is called free energy.
In particular, if $\beta = 1$, free energy is equal to the additive inverse of the logarithmic likelihood:

$$
    \log Z_{n}(X^{n}; 1)
    .
$$

<div class="end-of-statement" style="text-align: right">■</div>

#### Definition. Entropy
* $q$,
    * true dsitribution

$$
    S
    :=
    -
    \int_{\mathbb{R}}
        q(x)
        \log q(x)
    \ dx
    .
$$

<div class="QED" style="text-align: right">$\Box$</div>

#### Definition emprical entropy
Let

$$
    S_{n}
    :=
    -
    \frac{1}{n}
    \sum_{i=1}^{n}
        \log q(X_{i})
    .
$$

$S_{n}$ is called emrical entropy.

<div class="end-of-statement" style="text-align: right">■</div>

By definition,

$$
\begin{eqnarray}
    \mathrm{E}
    \left[
        S_{n}
    \right]
    & = &
        S
    \label{equation_01_16}
    \\
    F_{n}(1)
    & = &
        - \log Z_{n}(X^{n}; 1)
    \nonumber
    \\
    F_{n}(1)
    & = &
        - \log Z_{n}(X^{n}; 1)
    \nonumber
    \\
    & = &
        - \log
        \left(
            \int_{W}
                \phi(w)
                \prod_{i=1}^{n}
                    p(X_{i} \mid w)
            \ dw
        \right)
    \nonumber
    \\
    & = &
        - \log
        \left(
            \int_{W}
                \phi(w)
                \prod_{i=1}^{n}
                    p(X_{i} \mid w)
            \ dw
        \right)
\end{eqnarray}
$$


### 1.2.2 Estimation and Generalization

$$
    F_{n}(1)
    =
    n S_{n}
    +

$$

